{
	"source": "https://dev.to/",
	"crawledAt": "2026-02-02T06:01:43.714Z",
	"summary": {
		"pagesAttempted": 10,
		"pagesExtracted": 5,
		"pagesSkipped": 5,
		"totalTokensEstimate": 6432,
		"startTime": "2026-02-02T06:01:28.009Z",
		"endTime": "2026-02-02T06:01:43.668Z"
	},
	"pages": [
		{
			"url": "https://dev.to/",
			"title": "DEV Community",
			"markdown": "## Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸\n\n### Jess Lee for The DEV Team ãƒ» Jan 22\n\n#githubchallenge #devchallenge #cli #githubcopilot",
			"chunks": [
				{
					"id": "home_chunk_1",
					"content": "## Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸\n\n### Jess Lee for The DEV Team ãƒ» Jan 22\n\n#githubchallenge #devchallenge #cli #githubcopilot",
					"tokensEstimate": 53,
					"sourceUrl": "https://dev.to/",
					"pageTitle": "DEV Community"
				}
			],
			"metadata": {
				"url": "https://dev.to/",
				"title": "DEV Community",
				"depth": 0,
				"crawledAt": "2026-02-02T06:01:34.235Z",
				"tokensEstimate": 53
			}
		},
		{
			"url": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
			"title": "Understanding AI Model (LLM) Parameters: A Chef's Guide",
			"markdown": "## What Are AI Model Parameters? Let Me Explain\n\nMy friend asked me yesterday, \"What does it mean when they say GPT-4 has 1.7 trillion parameters? What even are parameters?\"\n\nGreat question! I realized a lot of people hear these huge numbers 175 billion, 1.7 trillion and have no idea what they actually represent. So let me explain it the way I explained it to my friend, using something we both understand: cooking.\n\n## Let's Start With What We Know\n\nWhen you hear about AI models, you'll see numbers like:\n\n- GPT-3 has 175 billion parameters- GPT-4 has around 1.7 trillion parameters- Claude 3.5 Sonnet has roughly 400 billion parameters\n\nThese numbers are huge. But what do they mean? Are they **storing** that many **facts**? That many **sentences**? Let me break it down.\n\n## Think About a Chef\n\nImagine you're learning to **cook**. You start with **recipes**, **ingredients**, and **lots** of **practice**. Over time, you don't just follow recipes anymore you *understand* cooking. You know when to add more **salt**, how long to cook something, which **spices** work together.\n\nAI models work the same way.\n\n### The Raw Ingredients = Training Data\n\nWhen we train an AI model, we feed it massive amounts of **text** books, **websites**, **conversations**, **code**, **articles**. Think of this as the raw ingredients. Just having flour, **spices**, and **vegetables** doesn't make you a good cook. You need to learn how to use them.\n\n### The Chef's Skill = Parameters\n\nHere's where parameters come in.\n\nParameters are **not** the training data. They're what the model **learned** from that data. Think of them as the chef's skill, experience, and intuition.\n\nWhen a chef cooks biryani 1,000 times, they learn:\n\n- Exactly how much salt balances the rice- When to add the spices for maximum flavour- How long to cook it based on the heat- How to adjust if something goes wrong\n\n**They didn't memorize 1,000 biryani recipes**. They developed an *understanding* of how biryani works. That understanding those **tiny** **adjustments** and **decisions** stored in their mind that's what parameters are in AI.\n\n## How Does the Learning Actually Happen?\n\nThis is the most important part that many explanations skip.\n\nImagine a student chef learning to make biryani. Here's what happens:\n\n**Step 1:** They cook the biryani (using their current knowledge)\n\n**Step 2:** The master chef tastes it and says, \"Too much salt\" or \"Not enough spice\"\n\n**Step 3:** The student adjusts their technique maybe they use half a teaspoon less salt next time, or add cardamom earlier\n\n**Step 4:** They cook again with these adjustments\n\n**Step 5:** Repeat this thousands of times\n\nAfter 1,000 attempts, the student doesn't need the master chef anymore. They've internalized the patterns. They *know* instinctively how to make great biryani.\n\n### This Is Exactly How AI Training Works\n\nThe AI model reads billions of sentences from its training data. For each sentence, it:\n\n- **Tries to predict the next word**â€” \"The cat sat on the ___\"- **Checks if it was right**â€” the actual word was \"mat\"- **Adjusts its internal numbers (parameters)**to make better predictions next time- **Repeats this billions of times**across all the text\n\nThrough this process, the model isn't memorizing sentences. It's learning patterns:\n\n- Grammar rules (subjects come before verbs)- Word relationships (cats sit, birds fly)- Context (a river \"bank\" vs. a money \"bank\")- Reasoning patterns (cause and effect)\n\nBy the end of training, those 1.7 trillion parameters contain all these learned patterns. They're like the compressed wisdom the model gained from reading all that text.\n\n## So What Does \"1.7 Trillion Parameters\" Actually Mean?\n\nWhen we say GPT-4 has 1.7 trillion parameters, we're saying it has 1.7 trillion tiny adjustable numbers that store all this learned knowledge.\n\nEach parameter is like a single tiny piece of knowledge:\n\n- \"When this word appears, slightly increase the chance of that word coming next\"- \"In this context, this phrase structure is more likely\"- \"These concepts are related in this way\"\n\nMore parameters = more capacity to store subtle patterns and nuances. It's why larger models can often understand context better and give more sophisticated responses.\n\nBut here's the key: **more parameters doesn't mean more facts memorized**. It means more ability to understand the *patterns* in language.\n\n## When You Ask ChatGPT a Question\n\nNow when you type a question into ChatGPT, here's what happens:\n\nYou're like a customer ordering food. The AI chef doesn't look up your exact question in a database. Instead, it uses all those 1.7 trillion learned patterns (parameters) to generate a fresh response, right there on the spot.\n\nThat's why it can answer questions it has never seen before. Just like a skilled chef can create a new dish without having the exact recipe, the AI can create new answers using the patterns it learned.\n\n## Why Smaller Models Can Still Be Good\n\nYou might wonder: if more parameters are better, why do we have smaller models?\n\nThink about it this way. You don't need a Michelin star chef to make good everyday food. Sometimes a home cook with good fundamentals can make an excellent meal.\n\nNewer models like GPT-4o (around 200 billion parameters) are designed smarter. They might have fewer parameters, but they're organized more efficiently. They can still perform really well for most tasks while being:\n\n- Faster to respond- Cheaper to run- Easier to use on different devices\n\n## The Simple Truth\n\nSo when someone asks you what AI parameters are, tell them this:\n\n**Parameters are the learned knowledge stored inside the AI model. They're created through billions of training examples, where the model keeps adjusting itself to make better predictions. They're not memorized facts they're patterns and relationships the model discovered in language.**\n\nIt's like the difference between someone who memorized a cookbook and a chef who understands *why* ingredients work together. The AI has 1.7 trillion tiny pieces of understanding that help it generate intelligent responses to questions it has never seen before.\n\nThat's it. That's what parameters are.\n\n## But Wait What About RAG and Fine-tuning?\n\nNow here's where it gets even more interesting. My friend then asked, \"But what about when people talk about **RAG** or **fine-tuning**? How does that fit in?\"\n\nGreat question! Let me extend our cooking analogy.\n\n### LLMs Are Like Frozen Food\n\nThink of a trained LLM (like GPT-4 or Claude) as high quality frozen food. It's already prepared, cooked, and ready. The chef (the company that trained it) has already done the hard work. All those parameters? They're frozen locked in place.\n\nBut you can still make it better or customize it for your needs. Here are two ways:\n\n### RAG (Retrieval Augmented Generation) = Adding Fresh Ingredients\n\nImagine you have frozen biryani. It's good, but you want to make it your own. So you:\n\n- Heat it up- Add fresh coriander on top- Mix in some raita- Maybe add extra fried onions\n\nYou didn't change the frozen biryani itself. You just added fresh ingredients around it to make it better and more customized.\n\n**This is exactly what RAG does.**\n\nWhen you use **RAG**, you're not changing the AI's parameters (the frozen food stays frozen). Instead, you're giving it fresh, relevant information right when it needs it:\n\n- You ask: \"What did our company discuss in last week's meeting?\"- RAG system searches your company documents- It finds the meeting notes- It gives those notes to the AI along with your question- The AI uses its frozen knowledge (parameters) + the fresh information (meeting notes) to answer\n\nThe base model stays the same, but you've enhanced it with up-to-date, specific information. Just like adding fresh ingredients to frozen food.\n\n### Fine-tuning = Making a New Dish From Frozen Food\n\nNow imagine something different. You take that frozen biryani and decide to completely remake it:\n\n- You add paneer and make it paneer biryani- Or add extra vegetables and spices to create a completely new flavour profile- You're essentially creating a new dish using the frozen food as a base\n\n**This is fine-tuning.**\n\nWhen you **fine tune** an AI model, you're actually **unfreezing some of those parameters** and training them again on your specific data:\n\n- You start with the base model ( **frozen food**)- You train it on your specific examples (adding new ingredients and cooking it differently)- The parameters adjust to your specific use case- You end up with a **customized**model\n\nFor example, a hospital might fine tune GPT-4 on medical records to create a specialized medical AI. The base knowledge is still there (language patterns, reasoning), but now it's been adjusted to understand medical terminology and patterns better.\n\n### The Key Difference\n\n**RAG** = Keep the model frozen, just add fresh information when needed\n\n- Fast to set up- No need to retrain anything- Perfect for adding new, changing information\n\n**Fine-tuning** = Unfreeze and adjust the model itself\n\n- Takes more time and resources- Changes the actual parameters- Perfect for specialized tasks or domain specific knowledge\n\n**Both approaches use the same idea**: the pre trained model (with its trillions of parameters) is your starting point your frozen food. But depending on what you need, you either add fresh ingredients around it (**RAG**) or transform it into something new (**fine tuning**).\n\n*Note: The exact parameter counts for newer models are often estimates, as companies don't always publish official numbers. But the concept remains the same parameters represent the learned patterns, not the raw data.*\n\n**Thanks\nSreeni Ramadorai**",
			"chunks": [
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_1",
					"content": "## What Are AI Model Parameters? Let Me Explain\n\nMy friend asked me yesterday, \"What does it mean when they say GPT-4 has 1.7 trillion parameters? What even are parameters?\"\n\nGreat question! I realized a lot of people hear these huge numbers 175 billion, 1.7 trillion and have no idea what they actually represent. So let me explain it the way I explained it to my friend, using something we both understand: cooking.\n\n## Let's Start With What We Know\n\nWhen you hear about AI models, you'll see numbers like:\n\n- GPT-3 has 175 billion parameters- GPT-4 has around 1.7 trillion parameters- Claude 3.5 Sonnet has roughly 400 billion parameters\n\nThese numbers are huge. But what do they mean? Are they **storing** that many **facts**? That many **sentences**? Let me break it down.\n\n## Think About a Chef\n\nImagine you're learning to **cook**. You start with **recipes**, **ingredients**, and **lots** of **practice**. Over time, you don't just follow recipes anymore you *understand* cooking. You know when to add more **salt**, how long to cook something, which **spices** work together.\n\nAI models work the same way.\n\n### The Raw Ingredients = Training Data\n\nWhen we train an AI model, we feed it massive amounts of **text** books, **websites**, **conversations**, **code**, **articles**. Think of this as the raw ingredients. Just having flour, **spices**, and **vegetables** doesn't make you a good cook. You need to learn how to use them.",
					"tokensEstimate": 357,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_2",
					"content": "### The Chef's Skill = Parameters\n\nHere's where parameters come in.\n\nParameters are **not** the training data. They're what the model **learned** from that data. Think of them as the chef's skill, experience, and intuition.\n\nWhen a chef cooks biryani 1,000 times, they learn:\n\n- Exactly how much salt balances the rice- When to add the spices for maximum flavour- How long to cook it based on the heat- How to adjust if something goes wrong\n\n**They didn't memorize 1,000 biryani recipes**. They developed an *understanding* of how biryani works. That understanding those **tiny** **adjustments** and **decisions** stored in their mind that's what parameters are in AI.",
					"tokensEstimate": 166,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_3",
					"content": "## How Does the Learning Actually Happen?\n\nThis is the most important part that many explanations skip.\n\nImagine a student chef learning to make biryani. Here's what happens:\n\n**Step 1:** They cook the biryani (using their current knowledge)\n\n**Step 2:** The master chef tastes it and says, \"Too much salt\" or \"Not enough spice\"\n\n**Step 3:** The student adjusts their technique maybe they use half a teaspoon less salt next time, or add cardamom earlier\n\n**Step 4:** They cook again with these adjustments\n\n**Step 5:** Repeat this thousands of times\n\nAfter 1,000 attempts, the student doesn't need the master chef anymore. They've internalized the patterns. They *know* instinctively how to make great biryani.",
					"tokensEstimate": 176,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_4",
					"content": "### This Is Exactly How AI Training Works\n\nThe AI model reads billions of sentences from its training data. For each sentence, it:\n\n- **Tries to predict the next word**â€” \"The cat sat on the ___\"- **Checks if it was right**â€” the actual word was \"mat\"- **Adjusts its internal numbers (parameters)**to make better predictions next time- **Repeats this billions of times**across all the text\n\nThrough this process, the model isn't memorizing sentences. It's learning patterns:\n\n- Grammar rules (subjects come before verbs)- Word relationships (cats sit, birds fly)- Context (a river \"bank\" vs. a money \"bank\")- Reasoning patterns (cause and effect)\n\nBy the end of training, those 1.7 trillion parameters contain all these learned patterns. They're like the compressed wisdom the model gained from reading all that text.",
					"tokensEstimate": 203,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_5",
					"content": "## So What Does \"1.7 Trillion Parameters\" Actually Mean?\n\nWhen we say GPT-4 has 1.7 trillion parameters, we're saying it has 1.7 trillion tiny adjustable numbers that store all this learned knowledge.\n\nEach parameter is like a single tiny piece of knowledge:\n\n- \"When this word appears, slightly increase the chance of that word coming next\"- \"In this context, this phrase structure is more likely\"- \"These concepts are related in this way\"\n\nMore parameters = more capacity to store subtle patterns and nuances. It's why larger models can often understand context better and give more sophisticated responses.\n\nBut here's the key: **more parameters doesn't mean more facts memorized**. It means more ability to understand the *patterns* in language.",
					"tokensEstimate": 186,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_6",
					"content": "## When You Ask ChatGPT a Question\n\nNow when you type a question into ChatGPT, here's what happens:\n\nYou're like a customer ordering food. The AI chef doesn't look up your exact question in a database. Instead, it uses all those 1.7 trillion learned patterns (parameters) to generate a fresh response, right there on the spot.\n\nThat's why it can answer questions it has never seen before. Just like a skilled chef can create a new dish without having the exact recipe, the AI can create new answers using the patterns it learned.",
					"tokensEstimate": 132,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_7",
					"content": "## Why Smaller Models Can Still Be Good\n\nYou might wonder: if more parameters are better, why do we have smaller models?\n\nThink about it this way. You don't need a Michelin star chef to make good everyday food. Sometimes a home cook with good fundamentals can make an excellent meal.\n\nNewer models like GPT-4o (around 200 billion parameters) are designed smarter. They might have fewer parameters, but they're organized more efficiently. They can still perform really well for most tasks while being:\n\n- Faster to respond- Cheaper to run- Easier to use on different devices",
					"tokensEstimate": 143,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_8",
					"content": "## The Simple Truth\n\nSo when someone asks you what AI parameters are, tell them this:\n\n**Parameters are the learned knowledge stored inside the AI model. They're created through billions of training examples, where the model keeps adjusting itself to make better predictions. They're not memorized facts they're patterns and relationships the model discovered in language.**\n\nIt's like the difference between someone who memorized a cookbook and a chef who understands *why* ingredients work together. The AI has 1.7 trillion tiny pieces of understanding that help it generate intelligent responses to questions it has never seen before.\n\nThat's it. That's what parameters are.\n\n## But Wait What About RAG and Fine-tuning?\n\nNow here's where it gets even more interesting. My friend then asked, \"But what about when people talk about **RAG** or **fine-tuning**? How does that fit in?\"\n\nGreat question! Let me extend our cooking analogy.\n\n### LLMs Are Like Frozen Food\n\nThink of a trained LLM (like GPT-4 or Claude) as high quality frozen food. It's already prepared, cooked, and ready. The chef (the company that trained it) has already done the hard work. All those parameters? They're frozen locked in place.\n\nBut you can still make it better or customize it for your needs. Here are two ways:",
					"tokensEstimate": 321,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_9",
					"content": "### RAG (Retrieval Augmented Generation) = Adding Fresh Ingredients\n\nImagine you have frozen biryani. It's good, but you want to make it your own. So you:\n\n- Heat it up- Add fresh coriander on top- Mix in some raita- Maybe add extra fried onions\n\nYou didn't change the frozen biryani itself. You just added fresh ingredients around it to make it better and more customized.\n\n**This is exactly what RAG does.**\n\nWhen you use **RAG**, you're not changing the AI's parameters (the frozen food stays frozen). Instead, you're giving it fresh, relevant information right when it needs it:\n\n- You ask: \"What did our company discuss in last week's meeting?\"- RAG system searches your company documents- It finds the meeting notes- It gives those notes to the AI along with your question- The AI uses its frozen knowledge (parameters) + the fresh information (meeting notes) to answer\n\nThe base model stays the same, but you've enhanced it with up-to-date, specific information. Just like adding fresh ingredients to frozen food.",
					"tokensEstimate": 254,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_10",
					"content": "### Fine-tuning = Making a New Dish From Frozen Food\n\nNow imagine something different. You take that frozen biryani and decide to completely remake it:\n\n- You add paneer and make it paneer biryani- Or add extra vegetables and spices to create a completely new flavour profile- You're essentially creating a new dish using the frozen food as a base\n\n**This is fine-tuning.**\n\nWhen you **fine tune** an AI model, you're actually **unfreezing some of those parameters** and training them again on your specific data:\n\n- You start with the base model ( **frozen food**)- You train it on your specific examples (adding new ingredients and cooking it differently)- The parameters adjust to your specific use case- You end up with a **customized**model\n\nFor example, a hospital might fine tune GPT-4 on medical records to create a specialized medical AI. The base knowledge is still there (language patterns, reasoning), but now it's been adjusted to understand medical terminology and patterns better.",
					"tokensEstimate": 248,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				},
				{
					"id": "sreeni5018_understanding_ai_model_llm_parameters_a_chunk_11",
					"content": "### The Key Difference\n\n**RAG** = Keep the model frozen, just add fresh information when needed\n\n- Fast to set up- No need to retrain anything- Perfect for adding new, changing information\n\n**Fine-tuning** = Unfreeze and adjust the model itself\n\n- Takes more time and resources- Changes the actual parameters- Perfect for specialized tasks or domain specific knowledge\n\n**Both approaches use the same idea**: the pre trained model (with its trillions of parameters) is your starting point your frozen food. But depending on what you need, you either add fresh ingredients around it (**RAG**) or transform it into something new (**fine tuning**).\n\n*Note: The exact parameter counts for newer models are often estimates, as companies don't always publish official numbers. But the concept remains the same parameters represent the learned patterns, not the raw data.*\n\n**Thanks\nSreeni Ramadorai**",
					"tokensEstimate": 222,
					"sourceUrl": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
					"pageTitle": "Understanding AI Model (LLM) Parameters: A Chef's Guide"
				}
			],
			"metadata": {
				"url": "https://dev.to/sreeni5018/understanding-ai-model-llm-parameters-a-chefs-guide-4469",
				"title": "Understanding AI Model (LLM) Parameters: A Chef's Guide",
				"depth": 1,
				"crawledAt": "2026-02-02T06:01:36.274Z",
				"tokensEstimate": 2407
			}
		},
		{
			"url": "https://dev.to/evanlausier/the-66-problem-1c3m",
			"title": "The 66% Problem",
			"markdown": "[![Cover image for The 66% Problem](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Ftq2abfta1rmznnlwz84e.jpeg)](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Ftq2abfta1rmznnlwz84e.jpeg)\n\nI spent three hours last Tuesday chasing a bug that didn't exist.\n\nThe code looked perfect. It was syntactically correct, followed best practices, and even had thoughtful comments explaining what each function did. The problem was that one of those functions was solving a problem I never asked it to solve. Claude had decided, in its infinite pattern-matching wisdom, that my API endpoint needed pagination. I hadn't asked for pagination. I didn't want pagination. But there it was, breaking my response structure in ways that took me longer to diagnose than it would have taken to write the whole thing myself.\n\nThis is the 66% problem.\n\nAccording to Stack Overflow's latest developer survey of over 90,000 developers, 66% said their biggest frustration with AI coding assistants is that the code is \"almost right, but not quite.\" Another 45% said debugging AI-generated code takes more work than it's worth.\n\nI find those numbers oddly comforting. Not because I enjoy suffering, but because it means I'm not losing my mind. The tools that were supposed to make me faster have introduced a new category of bug that didn't exist three years ago: the bug that looks like working code.\n\nHere's the thing about completely wrong code. It fails loudly. It throws errors. It refuses to compile. Your test suite catches it. You fix it and move on with your life. But almost-right code? That's the code that passes your tests, ships to staging, and then does something subtly insane at 2am when your biggest client runs a batch job you forgot they were running.\n\nThe old bugs were honest. They announced themselves. These new bugs are polite. They wait.\n\nI've been writing code professionally for decades... I've made every mistake you can make. I've shipped SQL injection vulnerabilities. I've accidentally deleted production data. I once re-imaged over a production database locking myself out.Those were my mistakes, and I understood them immediately when they blew up. The feedback loop was tight: I did something dumb, the system complained, I learned not to do that again.\n\nThe AI-generated bugs don't work that way. When something breaks now, my first question isn't \"what did I do wrong?\" It's \"what did the AI do that I didn't notice?\" That's a fundamentally different kind of debugging. Instead of understanding my own logic, I'm reverse-engineering someone else's assumptions about what I probably wanted.\n\nMicrosoft Research published a study earlier this year that quantified this. They tested nine different AI models on SWE-bench Lite, a benchmark of 300 real-world debugging tasks. The best performer, Claude 3.7 Sonnet, solved 48.4% of them. Less than half. These weren't exotic edge cases. They were the kinds of bugs that wouldn't trip up an experienced developer.\n\nThe models are phenomenal at writing code. They struggle to fix it.\n\nThis makes a perverse kind of sense when you think about how they work. Code generation is pattern completion. You give the model a prompt, it predicts what code probably comes next based on billions of examples. That's genuinely useful for boilerplate, for syntax you've forgotten, for exploring unfamiliar libraries. But debugging isn't pattern completion. Debugging is hypothesis testing. It requires understanding what the code is supposed to do, what it's actually doing, and why those two things are different.\n\nThat \"why\" is where everything falls apart. The AI doesn't know why your system is architected the way it is. It doesn't know about the business rule your CEO insisted on in 2019 that makes no logical sense but accounts for 40% of your revenue. It doesn't know that your database schema has a quirk because you migrated from Oracle fifteen years ago and nobody wants to touch it. It just sees patterns and matches them.\n\nThe METR randomized trial from July 2025 found something that should concern all of us. They had experienced open-source developers complete tasks with and without AI assistance. The AI group was 19% slower on average. But here's the part that keeps me up at night: they believed they were 24% faster. Before starting, participants predicted AI would speed them up. After finishing, even with slower results, they still thought it had helped.\n\nWe're not just getting almost-right code. We're getting almost-right code while feeling productive. The dopamine hit of instant completion masks the debugging debt accumulating behind us.\n\nI'm not going to tell you to stop using AI tools. I use them constantly. But I've started treating them differently than I did a year ago. I used to accept suggestions and move on. Now I read every line like it was written by a junior developer who's very confident and moderately competent. Because that's essentially what it is.\n\nThe 66% aren't complaining because the tools are bad. They're complaining because the tools are good enough to be dangerous. A hammer that misses the nail is annoying. A hammer that hits almost the right spot is how you end up with a crooked house.\n\nI don't have a solution. I'm not sure anyone does yet. The tools will get better. The context windows will get longer. The models will learn to ask clarifying questions instead of assuming. Maybe.\n\nUntil then, I'm keeping my print statements close and my test coverage closer. Some skills don't need to be automated. They need to be sharpened.",
			"chunks": [
				{
					"id": "evanlausier_the_66_problem_1c3m_chunk_1",
					"content": "[![Cover image for The 66% Problem](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Ftq2abfta1rmznnlwz84e.jpeg)](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2Ftq2abfta1rmznnlwz84e.jpeg)\n\nI spent three hours last Tuesday chasing a bug that didn't exist.\n\nThe code looked perfect. It was syntactically correct, followed best practices, and even had thoughtful comments explaining what each function did. The problem was that one of those functions was solving a problem I never asked it to solve. Claude had decided, in its infinite pattern-matching wisdom, that my API endpoint needed pagination. I hadn't asked for pagination. I didn't want pagination. But there it was, breaking my response structure in ways that took me longer to diagnose than it would have taken to write the whole thing myself.\n\nThis is the 66% problem.\n\nAccording to Stack Overflow's latest developer survey of over 90,000 developers, 66% said their biggest frustration with AI coding assistants is that the code is \"almost right, but not quite.\" Another 45% said debugging AI-generated code takes more work than it's worth.\n\nI find those numbers oddly comforting. Not because I enjoy suffering, but because it means I'm not losing my mind. The tools that were supposed to make me faster have introduced a new category of bug that didn't exist three years ago: the bug that looks like working code.\n\nHere's the thing about completely wrong code. It fails loudly. It throws errors. It refuses to compile. Your test suite catches it. You fix it and move on with your life. But almost-right code? That's the code that passes your tests, ships to staging, and then does something subtly insane at 2am when your biggest client runs a batch job you forgot they were running.\n\nThe old bugs were honest. They announced themselves. These new bugs are polite. They wait.",
					"tokensEstimate": 514,
					"sourceUrl": "https://dev.to/evanlausier/the-66-problem-1c3m",
					"pageTitle": "The 66% Problem"
				},
				{
					"id": "evanlausier_the_66_problem_1c3m_chunk_2",
					"content": "I've been writing code professionally for decades... I've made every mistake you can make. I've shipped SQL injection vulnerabilities. I've accidentally deleted production data. I once re-imaged over a production database locking myself out.Those were my mistakes, and I understood them immediately when they blew up. The feedback loop was tight: I did something dumb, the system complained, I learned not to do that again.\n\nThe AI-generated bugs don't work that way. When something breaks now, my first question isn't \"what did I do wrong?\" It's \"what did the AI do that I didn't notice?\" That's a fundamentally different kind of debugging. Instead of understanding my own logic, I'm reverse-engineering someone else's assumptions about what I probably wanted.\n\nMicrosoft Research published a study earlier this year that quantified this. They tested nine different AI models on SWE-bench Lite, a benchmark of 300 real-world debugging tasks. The best performer, Claude 3.7 Sonnet, solved 48.4% of them. Less than half. These weren't exotic edge cases. They were the kinds of bugs that wouldn't trip up an experienced developer.\n\nThe models are phenomenal at writing code. They struggle to fix it.\n\nThis makes a perverse kind of sense when you think about how they work. Code generation is pattern completion. You give the model a prompt, it predicts what code probably comes next based on billions of examples. That's genuinely useful for boilerplate, for syntax you've forgotten, for exploring unfamiliar libraries. But debugging isn't pattern completion. Debugging is hypothesis testing. It requires understanding what the code is supposed to do, what it's actually doing, and why those two things are different.\n\nThat \"why\" is where everything falls apart. The AI doesn't know why your system is architected the way it is. It doesn't know about the business rule your CEO insisted on in 2019 that makes no logical sense but accounts for 40% of your revenue. It doesn't know that your database schema has a quirk because you migrated from Oracle fifteen years ago and nobody wants to touch it. It just sees patterns and matches them.",
					"tokensEstimate": 533,
					"sourceUrl": "https://dev.to/evanlausier/the-66-problem-1c3m",
					"pageTitle": "The 66% Problem"
				},
				{
					"id": "evanlausier_the_66_problem_1c3m_chunk_3",
					"content": "The METR randomized trial from July 2025 found something that should concern all of us. They had experienced open-source developers complete tasks with and without AI assistance. The AI group was 19% slower on average. But here's the part that keeps me up at night: they believed they were 24% faster. Before starting, participants predicted AI would speed them up. After finishing, even with slower results, they still thought it had helped.\n\nWe're not just getting almost-right code. We're getting almost-right code while feeling productive. The dopamine hit of instant completion masks the debugging debt accumulating behind us.\n\nI'm not going to tell you to stop using AI tools. I use them constantly. But I've started treating them differently than I did a year ago. I used to accept suggestions and move on. Now I read every line like it was written by a junior developer who's very confident and moderately competent. Because that's essentially what it is.\n\nThe 66% aren't complaining because the tools are bad. They're complaining because the tools are good enough to be dangerous. A hammer that misses the nail is annoying. A hammer that hits almost the right spot is how you end up with a crooked house.\n\nI don't have a solution. I'm not sure anyone does yet. The tools will get better. The context windows will get longer. The models will learn to ask clarifying questions instead of assuming. Maybe.\n\nUntil then, I'm keeping my print statements close and my test coverage closer. Some skills don't need to be automated. They need to be sharpened.",
					"tokensEstimate": 389,
					"sourceUrl": "https://dev.to/evanlausier/the-66-problem-1c3m",
					"pageTitle": "The 66% Problem"
				}
			],
			"metadata": {
				"url": "https://dev.to/evanlausier/the-66-problem-1c3m",
				"title": "The 66% Problem",
				"depth": 1,
				"crawledAt": "2026-02-02T06:01:37.439Z",
				"tokensEstimate": 1436
			}
		},
		{
			"url": "https://dev.to/devteam/join-the-github-copilot-cli-challenge-win-github-universe-tickets-copilot-pro-subscriptions-and-50af",
			"title": "Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸",
			"markdown": "[![Cover image for Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F6kv3h80vr00d635c9jwi.png)](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F6kv3h80vr00d635c9jwi.png)\n\nWe're excited to announce our newest challenge with [GitHub](https://github.com/)!\n\nRunning through **February 15**, the [GitHub Copilot CLI Challenge](https://dev.to/challenges/github-2026-01-21) invites you to experience the power of GitHub Copilot directly in your terminal.\n\nGitHub Copilot CLI brings AI-powered coding assistance to your command line, enabling you to build, debug, and understand code through natural language conversations.\n\nWhether you're building productivity tools, fun experiments, or solving everyday problems, this challenge is the perfect opportunity to explore what's possible when AI meets the command line.\n\nWe have some really great prizes for this challenge, and there are many opportunities to win! Read on to learn more.\n\n## Our Prompt\n\n**Your mandate is to build an application using GitHub Copilot CLI.**\nWhat should you build? That's entirely up to you! Here are some ideas to get you started:\n\n- **Productivity boosters:**Tools that make your daily workflow smoother- **Fun experiments:**That silly idea you've always wanted an excuse to build- **Problem solvers:**Solutions to common pain points you or others face- **Creative utilities:**Unique tools that showcase what Copilot CLI can do\n\nThe most important aspect? Show us how GitHub Copilot CLI enhances your development process and helps you build something awesome.\n\n## Prizes\n\n**Three Winners** will each receive:\n\n- $1,000 USD- Ticket to GitHub Universe 2026 (October 28-29)- Exclusive DEV Badge\n\n**25 Runner-Ups** will each receive:\n\n- 1-year GitHub Copilot Pro+ subscription- Exclusive DEV Badge\n\n**All Participants** with a valid submission will receive a completion badge on their DEV profile.\n\n### Getting Started with GitHub Copilot CLI ðŸš€\n\nReady to dive in? Check out the GitHub Copilot CLI repository:\n\n## ![GitHub logo](https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fassets.dev.to%2Fassets%2Fgithub-logo-5a155e1f9a670af7944dd5e12375bc76ed542ea80224905ecaf878b9157cdefc.svg) [github](https://github.com/github) / [copilot-cli](https://github.com/github/copilot-cli)\n\n### GitHub Copilot CLI brings the power of Copilot coding agent directly to your terminal.\n\n## GitHub Copilot CLI (Public Preview)\n\nThe power of GitHub Copilot, now in your terminal.\n\nGitHub Copilot CLI brings AI-powered coding assistance directly to your command line, enabling you to build, debug, and understand code through natural language conversations. Powered by the same agentic harness as GitHub's Copilot coding agent, it provides intelligent assistance while staying deeply integrated with your GitHub workflow.\n\nSee [our official documentation](https://docs.github.com/copilot/concepts/agents/about-copilot-cli) for more information.\n\n[[Image: Image of the splash screen for the Copilot CLI]](https://private-user-images.githubusercontent.com/1682753/538962279-f40aa23d-09dd-499e-9457-1d57d3368887.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjkxMjE3OTQsIm5iZiI6MTc2OTEyMTQ5NCwicGF0aCI6Ii8xNjgyNzUzLzUzODk2MjI3OS1mNDBhYTIzZC0wOWRkLTQ5OWUtOTQ1Ny0xZDU3ZDMzNjg4ODcucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDEyMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAxMjJUMjIzODE0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NjliM2IxZWFhNmVlN2RkYjk4MmJmYzFjODQ3ZTNmNzIzOGMxOWI0MzMyMzI2ZjljMzZiNTQyNDRkZTRlMGM0YyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WVVMVgwBvsEcv-Ib-5fWyy8C0oE4_KAfmP9NvKw4p8I)\n\n## ðŸš€ Introduction and Overview\n\nWe're bringing the power of GitHub Copilot coding agent directly to your terminal. With GitHub Copilot CLI, you can work locally and synchronously with an AI agent that understands your code and GitHub context.\n\n- **Terminal-native development:**Work with Copilot coding agent directly in your command line â€” no context switching required.- **GitHub integration out of the box:**Access your repositories, issues, and pull requests using natural language, all authenticated with your existing GitHub account.- **Agentic capabilities:**Build, editâ€¦\n\n## Important Dates\n\n- January 22: GitHub Copilot CLI Challenge begins!- February 15: Submissions due at 11:59 PM PST- February 26: Winners Announced\n\nWe can't wait to see what you build with GitHub Copilot CLI! Questions about the challenge? Ask them below.\n\nGood luck and happy coding!",
			"chunks": [
				{
					"id": "devteam_join_the_github_copilot_cli_challenge_win_chunk_1",
					"content": "[![Cover image for Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F6kv3h80vr00d635c9jwi.png)](https://media2.dev.to/dynamic/image/width=1000,height=420,fit=cover,gravity=auto,format=auto/https%3A%2F%2Fdev-to-uploads.s3.amazonaws.com%2Fuploads%2Farticles%2F6kv3h80vr00d635c9jwi.png)\n\nWe're excited to announce our newest challenge with [GitHub](https://github.com/)!\n\nRunning through **February 15**, the [GitHub Copilot CLI Challenge](https://dev.to/challenges/github-2026-01-21) invites you to experience the power of GitHub Copilot directly in your terminal.\n\nGitHub Copilot CLI brings AI-powered coding assistance to your command line, enabling you to build, debug, and understand code through natural language conversations.\n\nWhether you're building productivity tools, fun experiments, or solving everyday problems, this challenge is the perfect opportunity to explore what's possible when AI meets the command line.\n\nWe have some really great prizes for this challenge, and there are many opportunities to win! Read on to learn more.",
					"tokensEstimate": 317,
					"sourceUrl": "https://dev.to/devteam/join-the-github-copilot-cli-challenge-win-github-universe-tickets-copilot-pro-subscriptions-and-50af",
					"pageTitle": "Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸"
				},
				{
					"id": "devteam_join_the_github_copilot_cli_challenge_win_chunk_2",
					"content": "## Our Prompt\n\n**Your mandate is to build an application using GitHub Copilot CLI.**\nWhat should you build? That's entirely up to you! Here are some ideas to get you started:\n\n- **Productivity boosters:**Tools that make your daily workflow smoother- **Fun experiments:**That silly idea you've always wanted an excuse to build- **Problem solvers:**Solutions to common pain points you or others face- **Creative utilities:**Unique tools that showcase what Copilot CLI can do\n\nThe most important aspect? Show us how GitHub Copilot CLI enhances your development process and helps you build something awesome.\n\n## Prizes\n\n**Three Winners** will each receive:\n\n- $1,000 USD- Ticket to GitHub Universe 2026 (October 28-29)- Exclusive DEV Badge\n\n**25 Runner-Ups** will each receive:\n\n- 1-year GitHub Copilot Pro+ subscription- Exclusive DEV Badge\n\n**All Participants** with a valid submission will receive a completion badge on their DEV profile.\n\n### Getting Started with GitHub Copilot CLI ðŸš€\n\nReady to dive in? Check out the GitHub Copilot CLI repository:\n\n## ![GitHub logo](https://media2.dev.to/dynamic/image/width=800%2Cheight=%2Cfit=scale-down%2Cgravity=auto%2Cformat=auto/https%3A%2F%2Fassets.dev.to%2Fassets%2Fgithub-logo-5a155e1f9a670af7944dd5e12375bc76ed542ea80224905ecaf878b9157cdefc.svg) [github](https://github.com/github) / [copilot-cli](https://github.com/github/copilot-cli)\n\n### GitHub Copilot CLI brings the power of Copilot coding agent directly to your terminal.",
					"tokensEstimate": 366,
					"sourceUrl": "https://dev.to/devteam/join-the-github-copilot-cli-challenge-win-github-universe-tickets-copilot-pro-subscriptions-and-50af",
					"pageTitle": "Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸"
				},
				{
					"id": "devteam_join_the_github_copilot_cli_challenge_win_chunk_3",
					"content": "## GitHub Copilot CLI (Public Preview)\n\nThe power of GitHub Copilot, now in your terminal.\n\nGitHub Copilot CLI brings AI-powered coding assistance directly to your command line, enabling you to build, debug, and understand code through natural language conversations. Powered by the same agentic harness as GitHub's Copilot coding agent, it provides intelligent assistance while staying deeply integrated with your GitHub workflow.\n\nSee [our official documentation](https://docs.github.com/copilot/concepts/agents/about-copilot-cli) for more information.\n\n[[Image: Image of the splash screen for the Copilot CLI]](https://private-user-images.githubusercontent.com/1682753/538962279-f40aa23d-09dd-499e-9457-1d57d3368887.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NjkxMjE3OTQsIm5iZiI6MTc2OTEyMTQ5NCwicGF0aCI6Ii8xNjgyNzUzLzUzODk2MjI3OS1mNDBhYTIzZC0wOWRkLTQ5OWUtOTQ1Ny0xZDU3ZDMzNjg4ODcucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI2MDEyMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNjAxMjJUMjIzODE0WiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NjliM2IxZWFhNmVlN2RkYjk4MmJmYzFjODQ3ZTNmNzIzOGMxOWI0MzMyMzI2ZjljMzZiNTQyNDRkZTRlMGM0YyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WVVMVgwBvsEcv-Ib-5fWyy8C0oE4_KAfmP9NvKw4p8I)",
					"tokensEstimate": 347,
					"sourceUrl": "https://dev.to/devteam/join-the-github-copilot-cli-challenge-win-github-universe-tickets-copilot-pro-subscriptions-and-50af",
					"pageTitle": "Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸"
				},
				{
					"id": "devteam_join_the_github_copilot_cli_challenge_win_chunk_4",
					"content": "## ðŸš€ Introduction and Overview\n\nWe're bringing the power of GitHub Copilot coding agent directly to your terminal. With GitHub Copilot CLI, you can work locally and synchronously with an AI agent that understands your code and GitHub context.\n\n- **Terminal-native development:**Work with Copilot coding agent directly in your command line â€” no context switching required.- **GitHub integration out of the box:**Access your repositories, issues, and pull requests using natural language, all authenticated with your existing GitHub account.- **Agentic capabilities:**Build, editâ€¦\n\n## Important Dates\n\n- January 22: GitHub Copilot CLI Challenge begins!- February 15: Submissions due at 11:59 PM PST- February 26: Winners Announced\n\nWe can't wait to see what you build with GitHub Copilot CLI! Questions about the challenge? Ask them below.\n\nGood luck and happy coding!",
					"tokensEstimate": 216,
					"sourceUrl": "https://dev.to/devteam/join-the-github-copilot-cli-challenge-win-github-universe-tickets-copilot-pro-subscriptions-and-50af",
					"pageTitle": "Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸"
				}
			],
			"metadata": {
				"url": "https://dev.to/devteam/join-the-github-copilot-cli-challenge-win-github-universe-tickets-copilot-pro-subscriptions-and-50af",
				"title": "Join the GitHub Copilot CLI Challenge! Win GitHub Universe Tickets, Copilot Pro+ Subscriptions and $1,000 in Cash ðŸ’¸",
				"depth": 1,
				"crawledAt": "2026-02-02T06:01:39.831Z",
				"tokensEstimate": 1245
			}
		},
		{
			"url": "https://dev.to/shlokaguptaa/ai-workflows-vs-ai-agents-explained-with-legos-581g",
			"title": "ELi5 : AI Workflows vs AI Agents, Explained with LEGOs",
			"markdown": "Ever dumped a pile of LEGOs on the floor?\n\nYes?\n\nWell then, you are already a step closer to understanding the difference between AI workflows and AI agents.\n\n### AI workflows: LEGO manual builds\n\nAn AI workflow is like opening a LEGO house kit and following the instruction manual from step 1 to step 12.\n\nYou know:\n\n- exactly which piece snaps where- the order of the steps- and what the final house will look like\n\nNothing is left to chance.\n\nAI workflows work the same way. They follow a *fixed control path*, a predefined sequence of steps.\n\nBut why do we even need workflows in the first place?\n\n#### Why Models Alone Arenâ€™t Enough\n\nModels are really good at tasks like drafting emails, writing text messages, generating blog content, creating images, onverting text to voice, and other stuff\n\nFor example, if I ask an LLM:\n\n*â€œHey, can you draft me a text to ask Sam out on a date?â€*\nAn LLM (based application) like ChatGPT or Gemini will do a great job...\n\n...but sometimes, they kinda suck!\n\nSay, I ask chat:\n\"When is my date with Sam?\"\nIt wonâ€™t have a clue.\n\nBut what makes LLMs/Models kinda suck sometimes?\n\nWhile, it's true that they have been trained on massive public datasets, they donâ€™t have access to your personal or proprietary data. Stuff like your calendar, emails, companyâ€™s internal documents, etc.\n\nSo whatâ€™s the solution?\nGive the model access to your data.(Not all of it. Be careful. Duh!)\n\nNow, when the LLM gets questions around time like:\n*â€œWhen is my date with Sam?â€*\nOR\n*\"When is my lunch?\"*\nOR\n*\"When is my meeting?\"*\n\nit will:\n\n- Query your calendar- Extract the relevant event- Summarize it- Respond to you\n\nThatâ€™s an AI workflow!\n\nNote that over here the model is NOT deciding what to do, itâ€™s following a pre-wired path:\nInput â†’ Retrieve â†’ Process â†’ Respond\n\nJust like a LEGO manual, the logic and path is fixed!\n\n#### What makes workflows awesome\n\nAI workflows are awesome because of:\n\n- Predictable behavior- Easy to reason about- Cheap and efficient (Like really cost friendly)- Same input â†’ same output\n\nYou have a ballpark figure of how many â€œpiecesâ€ (API calls, LLM calls, compute) it will take.\n\n#### The downside\n\nIf you didnâ€™t plan for a step, the system breaks.\n\nJust like realizing mid-build that the manual requires a rare LEGO piece you lost under the couch. Everything stops until a human fixes it. :/\n\nSay, in the AI workflow above, you ask:\nâ€œWhat should I wear for my date, given the weather?â€\n\nThe workflow will fail! Not because the question is hard, but because:\n\n- it doesnâ€™t have access to a weather API- it doesnâ€™t know how to fetch outfits- it wasnâ€™t designed for this path\n\nSure, you can fix this by adding a weather API, adding an image generation model, wiring everything together\n\nBut no matter how many modules you add, itâ€™s **still just a workflow**.\n\nIt is still a fixed, predefined path.\n\nNo matter how many extra tools you glue on, the workflow still canâ€™t decide to change the plan. When you need the system to rethink the plan itself, you donâ€™t need more steps, you need something with a goal and autonomy. Thatâ€™s where agents come in.\n\n### AI Agents: Free Builds With a Goal\n\nAn AI agent is like dumping a pile of LEGOs in front of a kid and saying:\n\nâ€œBuild me something I can live in.\"\n\nYou donâ€™t give the kid instructions. You give them a *goal*.\n\nThe kid then:\n\n- inspects the available pieces- decides to build a house- realizes theyâ€™re missing roof tiles- pivots to a cabinâ€¦ or a cave\n\nThey reason their way to the goal using whatever resources they have.\n\nSimilarly, with agents, you donâ€™t give the Model a pre defined path, you give:\n\n- a **goal**- a **set of tools**(APIs, vector databases, workflows, search)- permission to decide what to do next\n\nWhen you give models tools, a goal, and permission to decide what to do next, thatâ€™s when they start acting like agents.\n\nIn a workflow, you decide this once at design time. In an agent, the LLM decides this at runtime.\n\nBut the awesomeness of agents comes at a cost\n\nEvery decision , â€œShould I search the web?â€ , â€œShould I call this API?â€, â€œDo I need another refinement loop?â€ is another LLM reasoning step.\n\nThink of it like hiring a brilliant architect:\n\n- incredible ideas- lots of sketches- very expensive\n\nAgents rarely crash outright. instead, they might give you something technically valid but very wrong.\n\nLike a LEGO jail, when all you wanted was a small cabin.\n\n#### So When Should You Use Which?\n\nIf you need certainty and repeatability, workflows are your friend.\nYou know exactly what pieces exist, exactly how they fit together, and exactly how the system behaves. Basically, when you need a factory.\n\nIf you need adaptability in messy environments, agents make sense.\nThey can reason around missing pieces, try alternative approaches, and still deliver something when the path isnâ€™t clear.\n\nBut the most practical pattern is hybrid.\n\n- Let workflows handle the predictable assembly line- Drop agents into the steps that truly need flexible reasoning\n\nThis approach is called, Agentic Workflows, and itâ€™s how most real-world AI systems are being built today.\n\nManual where possible. Free build where necessary. Just like LEGOs.\n\n* * *\n\nRolling Credits:\n\n- YouTube videos- LLMs- Reddit",
			"chunks": [
				{
					"id": "shlokaguptaa_ai_workflows_vs_ai_agents_explained_w_chunk_1",
					"content": "Ever dumped a pile of LEGOs on the floor?\n\nYes?\n\nWell then, you are already a step closer to understanding the difference between AI workflows and AI agents.",
					"tokensEstimate": 39,
					"sourceUrl": "https://dev.to/shlokaguptaa/ai-workflows-vs-ai-agents-explained-with-legos-581g",
					"pageTitle": "ELi5 : AI Workflows vs AI Agents, Explained with LEGOs"
				},
				{
					"id": "shlokaguptaa_ai_workflows_vs_ai_agents_explained_w_chunk_2",
					"content": "### AI workflows: LEGO manual builds\n\nAn AI workflow is like opening a LEGO house kit and following the instruction manual from step 1 to step 12.\n\nYou know:\n\n- exactly which piece snaps where- the order of the steps- and what the final house will look like\n\nNothing is left to chance.\n\nAI workflows work the same way. They follow a *fixed control path*, a predefined sequence of steps.\n\nBut why do we even need workflows in the first place?",
					"tokensEstimate": 109,
					"sourceUrl": "https://dev.to/shlokaguptaa/ai-workflows-vs-ai-agents-explained-with-legos-581g",
					"pageTitle": "ELi5 : AI Workflows vs AI Agents, Explained with LEGOs"
				},
				{
					"id": "shlokaguptaa_ai_workflows_vs_ai_agents_explained_w_chunk_3",
					"content": "#### Why Models Alone Arenâ€™t Enough\n\nModels are really good at tasks like drafting emails, writing text messages, generating blog content, creating images, onverting text to voice, and other stuff\n\nFor example, if I ask an LLM:\n\n*â€œHey, can you draft me a text to ask Sam out on a date?â€*\nAn LLM (based application) like ChatGPT or Gemini will do a great job...\n\n...but sometimes, they kinda suck!\n\nSay, I ask chat:\n\"When is my date with Sam?\"\nIt wonâ€™t have a clue.\n\nBut what makes LLMs/Models kinda suck sometimes?\n\nWhile, it's true that they have been trained on massive public datasets, they donâ€™t have access to your personal or proprietary data. Stuff like your calendar, emails, companyâ€™s internal documents, etc.\n\nSo whatâ€™s the solution?\nGive the model access to your data.(Not all of it. Be careful. Duh!)\n\nNow, when the LLM gets questions around time like:\n*â€œWhen is my date with Sam?â€*\nOR\n*\"When is my lunch?\"*\nOR\n*\"When is my meeting?\"*\n\nit will:\n\n- Query your calendar- Extract the relevant event- Summarize it- Respond to you\n\nThatâ€™s an AI workflow!\n\nNote that over here the model is NOT deciding what to do, itâ€™s following a pre-wired path:\nInput â†’ Retrieve â†’ Process â†’ Respond\n\nJust like a LEGO manual, the logic and path is fixed!\n\n#### What makes workflows awesome\n\nAI workflows are awesome because of:\n\n- Predictable behavior- Easy to reason about- Cheap and efficient (Like really cost friendly)- Same input â†’ same output\n\nYou have a ballpark figure of how many â€œpiecesâ€ (API calls, LLM calls, compute) it will take.",
					"tokensEstimate": 379,
					"sourceUrl": "https://dev.to/shlokaguptaa/ai-workflows-vs-ai-agents-explained-with-legos-581g",
					"pageTitle": "ELi5 : AI Workflows vs AI Agents, Explained with LEGOs"
				},
				{
					"id": "shlokaguptaa_ai_workflows_vs_ai_agents_explained_w_chunk_4",
					"content": "#### The downside\n\nIf you didnâ€™t plan for a step, the system breaks.\n\nJust like realizing mid-build that the manual requires a rare LEGO piece you lost under the couch. Everything stops until a human fixes it. :/\n\nSay, in the AI workflow above, you ask:\nâ€œWhat should I wear for my date, given the weather?â€\n\nThe workflow will fail! Not because the question is hard, but because:\n\n- it doesnâ€™t have access to a weather API- it doesnâ€™t know how to fetch outfits- it wasnâ€™t designed for this path\n\nSure, you can fix this by adding a weather API, adding an image generation model, wiring everything together\n\nBut no matter how many modules you add, itâ€™s **still just a workflow**.\n\nIt is still a fixed, predefined path.\n\nNo matter how many extra tools you glue on, the workflow still canâ€™t decide to change the plan. When you need the system to rethink the plan itself, you donâ€™t need more steps, you need something with a goal and autonomy. Thatâ€™s where agents come in.",
					"tokensEstimate": 240,
					"sourceUrl": "https://dev.to/shlokaguptaa/ai-workflows-vs-ai-agents-explained-with-legos-581g",
					"pageTitle": "ELi5 : AI Workflows vs AI Agents, Explained with LEGOs"
				},
				{
					"id": "shlokaguptaa_ai_workflows_vs_ai_agents_explained_w_chunk_5",
					"content": "### AI Agents: Free Builds With a Goal\n\nAn AI agent is like dumping a pile of LEGOs in front of a kid and saying:\n\nâ€œBuild me something I can live in.\"\n\nYou donâ€™t give the kid instructions. You give them a *goal*.\n\nThe kid then:\n\n- inspects the available pieces- decides to build a house- realizes theyâ€™re missing roof tiles- pivots to a cabinâ€¦ or a cave\n\nThey reason their way to the goal using whatever resources they have.\n\nSimilarly, with agents, you donâ€™t give the Model a pre defined path, you give:\n\n- a **goal**- a **set of tools**(APIs, vector databases, workflows, search)- permission to decide what to do next\n\nWhen you give models tools, a goal, and permission to decide what to do next, thatâ€™s when they start acting like agents.\n\nIn a workflow, you decide this once at design time. In an agent, the LLM decides this at runtime.\n\nBut the awesomeness of agents comes at a cost\n\nEvery decision , â€œShould I search the web?â€ , â€œShould I call this API?â€, â€œDo I need another refinement loop?â€ is another LLM reasoning step.\n\nThink of it like hiring a brilliant architect:\n\n- incredible ideas- lots of sketches- very expensive\n\nAgents rarely crash outright. instead, they might give you something technically valid but very wrong.\n\nLike a LEGO jail, when all you wanted was a small cabin.",
					"tokensEstimate": 320,
					"sourceUrl": "https://dev.to/shlokaguptaa/ai-workflows-vs-ai-agents-explained-with-legos-581g",
					"pageTitle": "ELi5 : AI Workflows vs AI Agents, Explained with LEGOs"
				},
				{
					"id": "shlokaguptaa_ai_workflows_vs_ai_agents_explained_w_chunk_6",
					"content": "#### So When Should You Use Which?\n\nIf you need certainty and repeatability, workflows are your friend.\nYou know exactly what pieces exist, exactly how they fit together, and exactly how the system behaves. Basically, when you need a factory.\n\nIf you need adaptability in messy environments, agents make sense.\nThey can reason around missing pieces, try alternative approaches, and still deliver something when the path isnâ€™t clear.\n\nBut the most practical pattern is hybrid.\n\n- Let workflows handle the predictable assembly line- Drop agents into the steps that truly need flexible reasoning\n\nThis approach is called, Agentic Workflows, and itâ€™s how most real-world AI systems are being built today.\n\nManual where possible. Free build where necessary. Just like LEGOs.\n\n* * *\n\nRolling Credits:\n\n- YouTube videos- LLMs- Reddit",
					"tokensEstimate": 205,
					"sourceUrl": "https://dev.to/shlokaguptaa/ai-workflows-vs-ai-agents-explained-with-legos-581g",
					"pageTitle": "ELi5 : AI Workflows vs AI Agents, Explained with LEGOs"
				}
			],
			"metadata": {
				"url": "https://dev.to/shlokaguptaa/ai-workflows-vs-ai-agents-explained-with-legos-581g",
				"title": "ELi5 : AI Workflows vs AI Agents, Explained with LEGOs",
				"depth": 1,
				"crawledAt": "2026-02-02T06:01:40.488Z",
				"tokensEstimate": 1291
			}
		}
	]
}